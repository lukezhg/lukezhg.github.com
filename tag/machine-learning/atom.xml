<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[tags: machine learning | Chunlei's Blog]]></title>
  <link href="http://zhangchunlei.com/tag/machine-learning/atom.xml" rel="self"/>
  <link href="http://zhangchunlei.com/"/>
  <updated>2020-08-27T15:46:09+08:00</updated>
  <id>http://zhangchunlei.com/</id>
  <author>
    <name><![CDATA[chunlei]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[deep learning]]></title>
    <link href="http://zhangchunlei.com/blog/2017/08/25/deep-learning/"/>
    <updated>2017-08-25T11:00:00+08:00</updated>
    <id>http://zhangchunlei.com/blog/2017/08/25/deep-learning</id>
    <content type="html"><![CDATA[<p>机器学习是人工智能中非常重要的一个分支。而深度学习则是机器学习中一个重要的方向。所以人工智能、机器学习和深度学习三个概念的关系是：<br/>
【人工智能【机器学习【深度学习】】】</p>

<p>在教育领域和计算机科学领域的深度学习并不是一个概念。</p>

<p>这里主要尝试利用keras和python来进行深度学习模拟。</p>

<p>keras是一个深度学习模拟的良好平台，并且它完全基于python构建，具有简易性和扩展性。一个典型的keras模型如下：</p>

<pre><code>
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD

# Generate dummy data
import numpy as np
x_train = np.random.random((1000, 20))
y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)
x_test = np.random.random((100, 20))
y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)

model = Sequential()
# Dense(64) is a fully-connected layer with 64 hidden units.
# in the first layer, you must specify the expected input data shape:
# here, 20-dimensional vectors.
model.add(Dense(64, activation='relu', input_dim=20))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy',
              optimizer=sgd,
              metrics=['accuracy'])

model.fit(x_train, y_train,
          epochs=20,
          batch_size=128)
score = model.evaluate(x_test, y_test, batch_size=128)
</code></pre>


<p>上面这个例子是一个贯序模型，它是一条道走到头的。如果是多口输出或者有分叉结构的模型，这需要用函数式模型，见<a href="https://keras-cn.readthedocs.io/en/latest/getting_started/functional_API/">函数式模型文档</a>。</p>

<p>其他例子见：<a href="https://keras-cn.readthedocs.io/en/latest/getting_started/sequential_model/">官方文档</a></p>

<p>（1）数据定义<br/>
定义训练数据和检验数据，必要的时候需要对数据进行处理，从而使的数据的形状和大小符合要求。</p>

<p>（2）模型定义 <br/>
定义输入层、输出层以及中间的隐藏层，层的类别和神经元数量。</p>

<p>（3）训练<br/>
利用训练数据对模型进行fit，使得模型的参数与训练数据更好的吻合。</p>

<p>（4）检验<br/>
利用检验数据对模型及其参数进行检验，通常会依靠正确率以及gradient descent对模型进行评估和完善。</p>

<p>（5）应用<br/>
当一个模型经过训练之后能够很好的完成预测任务时，那么就可以保存模型以及相应的权重参数，在需要的时候直接调用完成任务即可。比如，讯飞的语言识别，其参数是经过大量数据的长时间训练得到的，但是我们输入语音后，后台可以及时给我们呈现文字，说明它也是调用了已有的参数，否者估计几天后才能收到讯飞发给我们的语音识别文字了。</p>

<p>机器学习可以用于：分类、聚类、回归、异常识别等。</p>

<p>还可以制作聊天记起，比如利用chatbot制作的聊天机器人，还具有学习新对话的能力。<br/>
http://127.0.0.1:8000/chat/</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Machine learning and Octave]]></title>
    <link href="http://zhangchunlei.com/blog/2013/11/03/machine-learning-and-octave/"/>
    <updated>2013-11-03T12:28:00+08:00</updated>
    <id>http://zhangchunlei.com/blog/2013/11/03/machine-learning-and-octave</id>
    <content type="html"><![CDATA[<p>Recently I joined NG' class of <a href="https://class.coursera.org/ml-004/class/index">Machine Learning</a></p>

<p>Summay of the main topics:</p>

<h3>Suprevised Learning</h3>

<p>linear regression<br/>
通过已有数据，估算线性函数的参数，然后通过自变量X估测因变量y的值。例如在拥有交易数据的情况下，通过房子本身的具体参数预测其市场价格。其中y是连续变量。当仅仅利用原始数据不能给出很好的预测时，可以考虑扩展X，比如原始变量只有x1, x2，扩张后可以包含x1, x2, x1*x2, x1<sup>2</sup> ,x2<sup>2,</sup> 这样就可以克服bias的可能性。</p>

<p>logistic regression<br/>
当y是二分变量时，比如根据肿瘤的形状估测其是否为恶性肿瘤。这个时候就要使用logistic regression了。思路与linear regression一样，当目标是做出真假的判断。实现的方法是利用logistic curve做变换，转变为linear regression。</p>

<p>neural networks<br/>
模拟神经元的作用模式，设置隐藏层，通过估算中间参数来达到预测的目的。</p>

<p>SVM<br/>
向量机适用于自变量X不是特比多时，如果有上万个自变量，那么这个时候SVM会很困难。向量机的核函数可以有多种选择，可以是线性的，也可以是gaussain kernel等。</p>

<h3>Unsupervised Learning</h3>

<p>K-means<br/>
聚类分析</p>

<p>PCA<br/>
主成分分析</p>

<p>Anomaly detection<br/>
异常识别</p>

<h3>Special applications/topics</h3>

<p>Recommender systems<br/>
例如根据用户对影片的评价，向用户推荐合适的影片。这种情景需要循环估算影片参数和用户参数，进而给出合适的推荐。</p>

<p>large scale machine learning<br/>
通过算法上技巧将巨型运算分解，如分解到多个计算机，或者分解为多个步骤的小运算。</p>

<h3>Advice on building a machine learning system</h3>

<p>Bias/variance<br/>
参考Ng的两张幻灯片。<br/>
<img src="https://raw.github.com/lukezhg/Freyja/master/highbias.png" alt="high bias" /><br/>
<img src="https://raw.github.com/lukezhg/Freyja/master/highvariance.png" alt="high variance" /></p>

<p>regularization<br/>
通过regularizations参数（如C值，lamda等）的控制，达到既不bias，也不overfit的目的。</p>

<p>deciding what to work on next<br/>
从简单开始，不断评估，逐渐优化，寻求正解。</p>

<p>evaluation of learning algorithms</p>

<p>learning curves</p>

<p>error analysis<br/>
I类错误：假阴性，明明是，结果预测说不是。<br/>
II类错误：假阳性，明明不是，结果预测说是。<br/>
Precision=truePositive/(truePositive+falsePositive)<br/>
Recall=truePositive/(truePositive+falseNegtive)<br/>
F score=2<em>P</em>R/(P+R)<br/>
通过F值可以在两者之间得到平衡，F值越大两者兼顾越好。</p>

<p>ceiling analysis</p>

<p>picture notes: G:\myfile\img\machinelearning</p>

<h3>Octave basics</h3>

<p><a href="http://www.gnu.org/software/octave/about.html">Octave</a></p>

<p>Here is the Basic Commands from Ng's class notes</p>

<pre><code>
PS1('>> '); % make pre short  
1==2 %false  
1~=2  
1 && 2 % AND  
1 || 0 % OR  
xor(1,0) % OR
a=3; % semicolon supressing output  
b='hi';  
disp(sprintf('2 decimals: %0.2f',a))  
a=pi;  
format long  
format short  
A=[1 2; 3 4; 5 6]  
ones(3,1)  
zeros(1,3)  
rand(1,3)  
hist(-6+sqrt(10)*(randn(1,10000)))  
size(A,1)  
save hello.txt v -ascii % save as text  
eye(6)  
length(A)  
load featuresX.dat  
load priceY.dat  
load('featuresX.dat')  
who  
clear priceY  
clear  
v=priceY(1:10)  
A(3,1)  
A(2,:) % ":" means every element along that row/column  
A([1 3],:) % get 1,3 row  
A(:,2)=[10;11;12]  
A=[A,[100;101;102]]  
A(:) % put all elements into a single vector  
C=[A B]  
C=[A; B]  
sum(A)  
prod(A)  
floor(A)  
ceil(A)  
max(A,[],1)  
max(A,[],2)  
max(A)  
flipud(eye(9))  
t=[0:0.01:0.98]  
y1=sin(2*pi*4*t);
y2=cos(2*pi*4*t);  
plot(t,y1);  
plot(t,y2,'r')  
xlabel('time')  
ylabel('value')  
legent('sin','cos')  
title('my plot')  
print -dpng 'myPlot.png'  
close  
figure(1);plot(t,y1);  
figure(2);plot(t,y2);  
subplot(1,2,1); % divides plot a 1x2 grid, acce  
axis([0.5 1 -1 1]) & x [0.5 1] y[-1 1]  
clf;
imagesc(A)  
imagesc(A), colorbar, colormap gray;  

indices=1:10;  
for i=indices,
   disp(i);
end;  

i=1;  
while i <=5;  
  v(i)=100;  
  i=i+1;  
end;  

i=1;  
while true,  
  v(i)=999;  
  i=i+1;  
  if i==6,  
    break;  
  end;  
end;  

v(1)=2;  
if v(1)==1,  
  disp('equal one')  
elseif v(1)==2,  
  disp('equal two')  
else  
  disp('not one or two')  
end;  

pwd  
ls  

addpath('C:users\ang\Desktop') % add octave search path  
</code></pre>


<p>mlclass-ex4-004 and mlclass-ex4-003 can be used in Application Example: Photo OCR</p>
]]></content>
  </entry>
  
</feed>
